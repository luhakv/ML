{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Юнит 5. Основные алгоритмы машинного обучения. Часть I \n",
    "### Skillfactory: DSPR-19\n",
    "### ML-3B. Классификация "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Классификация** — самая популярная задача в машинном обучении. Алгоритм в ней сортирует объекты по нескольким классам. Можно сравнить его с ребенком, который раскладывает игрушки по коробкам — собачек в одну, а кошечек в другую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть некоторое количество объектов, каждый из которых принадлежит определенной группе (**классу**). На обучающей выборке нам известны эти соотношения (известно, какой объект какому классу принадлежит). Нам требуется построить алгоритм на обучающей выборке, который сможет в будущем определять классы для новых объектов.\n",
    "\n",
    "**Какие задачи можно решать с помощью классификации?**\n",
    "\n",
    "На данный момент классификация используется в следующих сферах:\n",
    "\n",
    "- Спам-фильтры и прочие фильтры почтовых ящиков: скорее всего, ваш почтовый клиент умеет не только отделять спам, но и сортировать письма от социальных сетей и промоакции.\n",
    "- Определение языка: с этим мы сталкиваемся постоянно, когда браузер предлагает нам перевести страницу или когда мы используем онлайн-переводчик, не зная языка оригинала.\n",
    "- Анализ тональности: к примеру, алгоритм может распознать, отрицательный или положительный отзыв написал вам клиент.\n",
    "- Распознавание рукописных букв и цифр: на данный момент уже существуют программы, переводящие рукописный текст в печатный. Это возможно именно благодаря классификации.\n",
    "\n",
    "Рассмотрим чуть подробнее несколько крупных и часто встречающихся задач, которые можно решить с помощью алгоритмов классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача кредитного скоринга\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе данных предыдущих кредиторов банк решает, выдавать ли кредит клиенту.\n",
    "\n",
    "В такой задаче у нас всего два класса: **надежный заемщик** или **ненадежный**.\n",
    "\n",
    "Признаки обычно бывают всех типов:\n",
    "\n",
    "- бинарные (пол, наличие квартиры под залог, семейное положение);\n",
    "- номинальные (место проживания,профессия);\n",
    "- ординальные (образование, должность);\n",
    "- количественные (доход, возраст).\n",
    "\n",
    "Задача довольно классическая, редко требует долгой предобработки (в силу того, что для кредита нужно обязательно заполнять все поля, пропусков тоже не допускается).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача биометрической идентификации личности\n",
    "\n",
    "Для биометрической идентификации личности используют обычно снимок радужки глаза и/или отпечаток пальца.  Это изображения, поэтому к решению задачи требуется достаточно объемная подготовка данных. Кроме того, тут предельно важна максимально возможная точность.\n",
    "\n",
    "#### Задача категоризации текстовых документов\n",
    "\n",
    "Одна из нетривиальных задач — распределение документов по рубрикам.\n",
    "\n",
    "Здесь встречаются следующие признаки:\n",
    "\n",
    "- номинальные (автор, издание, год);\n",
    "- количественные (встречаемость слов и специфических терминов).\n",
    "\n",
    "Главная проблема такой задачи в том, что каждый документ может попасть в две рубрики. Кроме того, данные могут иметь большое количество пропусков.\n",
    "\n",
    "Подводя итог, можно сказать, что классификация используется там, где мы делим объекты на какие-то группы. Количество групп не имеет значения, однако оно должно быть конечным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B.2. Метрики качества классификации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как мы обучили классификатор, необходимо **оценить его качество**. Для этого у нас есть несколько метрик.\n",
    "\n",
    "Самая простая и понятная метрика — *Accuracy*. По сути, это просто доля объектов, которые алгоритм отнес к верному классу.\n",
    "\n",
    "Введем следующие обозначения.\n",
    "\n",
    "Тот класс, который мы диагностируем, назовем **позитивным**, а другой класс — **негативным**. \n",
    "\n",
    "Например, если мы хотим обучить алгоритм распознавать больных людей, то больные будут попадать в позитивный класс, а здоровые — в негативный.\n",
    "\n",
    "Тогда верно определенных больных мы обозначим за **TP** *(true positive)*, ошибочно определенных больных — за **FP** *(false positive)*, верно определенных здоровых — за **TN** *(true negative)*, ошибочно определенных здоровых — за **FN** *(false negative)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть:\n",
    "\n",
    "**TP** — истинно-положительные решения;  \n",
    "**TN** — истинно-отрицательные решения;  \n",
    "**FP** — ложно-положительные решения;  \n",
    "**FN** — ложно-отрицательные решения.\n",
    "\n",
    "### Accuracy = (TP+TN) / (TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно!**  \n",
    "Важно отметить, что у этой метрики есть довольно существенный недостаток. Она присваивает всем объектам одинаковый вес. Поэтому в случае несбалансированности классов она может давать нерелевантный результат.\n",
    "\n",
    "То есть, к примеру, классификатор может иметь *Accuracy* в районе 0,8 и при этом вообще не распознавать объекты из какого-то класса, если их очень мало. Поэтому обязательно необходимо проверять сбалансированность классов перед применением этой метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Точность и полнота**  \n",
    "Следующие важные метрики — _Precision_ (точность) и _Recall_ (полнота). Они вычисляются следующим образом:\n",
    "\n",
    "### Precision = TP / (TP + FP)  \n",
    "### Recall = TP / (TP + FN)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Точность классификации** — это доля объектов, действительно принадлежащих данному классу относительно всех объектов, которые алгоритм отнес к этому классу.\n",
    "\n",
    "**Полнота** — это доля найденных классификатором объектов, принадлежащих классу относительно всех объектов, которые принадлежат этому классу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F-мера**\n",
    "Чтобы найти оптимальное соотношение этих показателей, существует метрика, которая объединяет в себе сразу и точность, и полноту F — мера. F-мера является средним гармоническим между точностью и полнотой и вычисляется по следующей формуле:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F - мера = (2 * Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация в Python\n",
    "Для начала подгружаем библиотеки:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # функция, чтобы разбить данные на трейн и тест\n",
    "from sklearn.linear_model import LogisticRegression # наша модель для классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся встроенным датасетом, который содержит информацию об опухолях груди:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer # подгружаем датасет\n",
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь зададим зависимую и независимые переменные:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = breast_cancer.target ## Наша целевая переменная, 0 — если рака нет, 1 — если есть \n",
    "X = breast_cancer.data # X - признаки, по которым мы будем предсказывать рак "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем выборку на обучающую и тестовую и обучаем нашу модель:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.3)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готово! Теперь осталось только вычислить необходимые метрики:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9590643274853801\n",
      "0.9351851851851852\n",
      "1.0\n",
      "0.9665071770334929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "Y_predicted = model.predict(X_val)\n",
    "print(accuracy_score(Y_val,Y_predicted))\n",
    "print(precision_score(Y_val,Y_predicted))\n",
    "print(recall_score(Y_val,Y_predicted))\n",
    "print(f1_score(Y_val,Y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B.2.1\n",
    "Вы создали классификатор, который разделяет экономические и политические новости на два разных Telegram-канала, и хотите проверить его качество. За день вышло 15 политических новостей и 20 экономических.\n",
    "Ваш алгоритм из 15 политических новостей отметил 9 как экономические, а из 20 экономических — 6 как политические.\n",
    "Найдите метрику _Accuracy_.\n",
    "Ответ округлите до сотых."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pictures/solution3B_2_1.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.57\n"
     ]
    }
   ],
   "source": [
    "TP = 14\n",
    "FP = 6\n",
    "FN = 9\n",
    "TN = 6\n",
    "acc = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "print(f\"Accuracy = {round(acc,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3B2.2\n",
    "Загрузите встроенный в библиотеку sklearn датасет про ирисы с помощью функции load_iris. Обучите модель логистической регрессии (random_state=50, размер тестовой выборки 0.3) и укажите полученное значение метрики Accuracy.\n",
    "Ответ округлите до сотых. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import  load_iris # подгружаем датасет\n",
    "iris =  load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "# выведем описание датасета\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(50)\n",
    "# зададим зависимую и независимые переменные:\n",
    "Y = iris.target ## Наша целевая переменная, три класса - 0 - Setosa, 1 - Versicolor,  2 - Virginica\n",
    "X = iris.data # X - признаки, по которым мы будем предсказывать класс ириса\n",
    "\n",
    "# Разбиваем выборку на обучающую и тестовую и обучаем нашу модель:\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.3)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# предсказываем целевые значения на тестовой выборке и выводим accuracy\n",
    "Y_predicted = model.predict(X_val)\n",
    "accuracy = accuracy_score(Y_val,Y_predicted)\n",
    "\n",
    "print(f\"Accuracy = {round(accuracy,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
