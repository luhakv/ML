{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Юнит 5. Основные алгоритмы машинного обучения. Часть I \n",
    "### Skillfactory: DSPR-19\n",
    "### ML-4. Валидация данных и оценка модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### План модуля:\n",
    "\n",
    "- Разбиение выборки.\n",
    "- Метрики качества.\n",
    "- Underfitting и overfitting.\n",
    "- Дисбаланс выборки.\n",
    "- Визуализация процесса обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Разбиение выборки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разбиение выборки** — это разделение имеющихся данных на несколько частей для проведения процессов обучения и валидации алгоритма МО так, чтобы оба процесса выполнялись на полностью независимых наборах данных.\n",
    "\n",
    "**Какие бывают выборки:**\n",
    "\n",
    "- Обучающая — подмножество данных, на котором мы обучаем модель.\n",
    "- Валидационная — подмножество данных, на котором мы валидируем модель, то есть проверяем промежуточные результаты. Выборка нужна для проверки модели.\n",
    "- Тестовая — подмножество данных, на котором мы тестируем модель после проверки всевозможных гипотез.\n",
    "\n",
    "Обучаем на обучающей выборке: модель явно затачивается под обучающую выборку. Валидируем на валидационной и подкручиваем параметры модели: модель неявно затачивается под валидационную выборку. Тестовая выборка имитирует тестирование модели в реальных условиях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Почему не стоит обучать на всей выборке?\n",
    "Основная цель для нас — это получить модель с хорошей прогностической способностью. Нам не столько важен результат предсказания на нашей выборке (так как на ней нам уже известны все значения признаков), сколько важно уметь предсказывать значения целевой переменной для объектов, которые мы будем исследовать в будущем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как разбить выборку\n",
    "**сomplete CV** — полный скользящий контроль\n",
    "В данном случае оценка строится по всем возможным разбиениям. Важно упомянуть этот метод, однако стоит понимать, что даже при малых размерах длины обучающей выборки число выборки очень большое, и это затрудняет практическое применение данного метода. Полный скользящий контроль используют в теоретических исследованиях или в тех случаях (довольно редких), когда удается вывести вычислительную формулу, позволяющую реализовать вычисления.\n",
    "\n",
    "К примеру, для метода k ближайших соседней такая формула известна, об этом можно почитать тут. Но все же этот метод разбиения используется на практике крайне редко.\n",
    "\n",
    "**hold-out** — отложенная выборка\n",
    "Разбиваем выборку на обучающую, валидационную и, по желанию, на тестовую выборки. Обычно в соотношении 60/40 или 70/30, вместе с тестовой — 60/20/20 или 70/15/15.\n",
    "\n",
    "Данный метод чаще всего применяется в случае больших датасетов в силу того, что требует значительно меньше вычислительных мощностей, чем другие методы.\n",
    "\n",
    "Однако важно помнить, что оценка в этом методе сильно зависит от разбиения. Это плохо, так как оценка должна в первую очередь характеризовать сам алгоритм обучения, а не способ разбиения.\n",
    "\n",
    "**k-fold — cross-validation**, перекрёстная валидация\n",
    "Разбиваем выборку на k частей.\n",
    "Повторяем k раз: обучаем на k-1 частях, валидируем на оставшейся части.\n",
    "Усредняем значения метрики.\n",
    "Позволяет сделать оценку качества более робастной — устойчивой к помехам.\n",
    "Чаще всего k имеет значение 10 (или 5 в случае маленьких выборок).\n",
    "\n",
    "**t×k-fold кросс-валидация**\n",
    "\n",
    "Процедура выполняется t раз. Обучающая выборка случайным образом разбивается на k непересекающихся, одинаковых по объему частей. Производится k итераций. На каждой итерации происходит k-fold-разбиение.\n",
    "\n",
    "По сути, такой тип валидации — это k-fold валидация, которая повторяется t раз. Такой способ контроля обладает всеми преимуществами k-fold-валидации, но при этом добавляется возможность увеличивать число разбиений.\n",
    "\n",
    "**leave-one-out** — отложенный пример\n",
    "Предельный случай k-fold, при котором k равняется размеру всей выборки:\n",
    "\n",
    "Выбираем пример для валидации, обучаем на всех остальных.\n",
    "Выбираем пример для валидации, который ещё не видели, возвращаемся в пункт 1.\n",
    "\n",
    "Частный случай **leave-P-out**, при котором нужно перебрать все способы выбора P-элементов из выборки.  Большим недостатком данного метода является то, что он очень ресурсозатратен. Однако нельзя утверждать, что он вообще не используется. В некоторых методах обучения вычисление LOO получается заметно ускорить, и его использование становится возможным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проблемы при разбиении\n",
    "- Обучение на тестовой выборке.\n",
    "- В тренировочной и тестовой выборках оказываются данные разной природы.\n",
    "Пример: при классификации автомобилей в тренировочную выборку попали примеры с одними типами двигателей, а в тестовую — с другими.\n",
    "- В тренировочной и тестовой выборках оказываются примеры со схожими признаками.\n",
    "Пример: при обучении модели предсказывают пол, разные фотографии одного и того же человека попадают в разные выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация в Python\n",
    "Для разбиения выборки в Python есть специальная функция test_train_split из библиотеки Scikit-learn:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После этого мы должны обозначить нашу зависимую переменную (Y) и независимые (X) и с помощью этой функции создать обучающую и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.65,test_size=0.35, random_state=101)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_train_size_ — аргумент, отвечающий за размер обучающей выборки (доля).\n",
    "\n",
    "_random_state_ является необязательным аргументом. Но дело в том, что разбиение каждый раз будет разным. Если задать явным образом значение random_state, то генерируемые псевдослучайные величины будут иметь одни и те же значения при каждом запуске алгоритма.\n",
    "\n",
    "Для кросс-валидации также есть специальные функции. Например, ниже пример k-fold c двумя разбиениями на двух фолдах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]]) \n",
    "y = np.array([1, 2, 3, 4]) \n",
    "kf = KFold(n_splits=2)  #реализация разбиения\n",
    "kf.get_n_splits(X) #возвращает количество разбиений\n",
    "kf.split(X) #возвращает индексы для разбиения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Практика\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Разбиение выборки\n",
    "**Разбиение выборки** - это разделение имеющихся данных на несколько частей для проведения процессов обучения и валидации алгоритма машинного обучения таким образом, чтобы оба процесса выполнялись на полностью независимых наборах данных (чтобы при валидации алгоритм работал с полностью незнакомыми данными той же структуры, что и обучающий набор данных).\n",
    "\n",
    "### Какие бывают выборки\n",
    "- [Тренировочная выборка](https://developers.google.com/machine-learning/glossary/#training_set) - подмножество данных, на котором тренируется модель\n",
    "- [Валидационная выборка](https://developers.google.com/machine-learning/glossary/#validation_set) - подмножество данных, на котором модель настраивается (\"тюнится\", подгоняются параметры)\n",
    "- [Тестовая выборка](https://developers.google.com/machine-learning/glossary/#test_set) - подмножество данных, на котором тестируется модель после проверки всех возможных гипотез по улучшению модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Способы разбиения выборки\n",
    "\n",
    "1. **hold-out** (отложенная выборка)\n",
    "1. **k-fold** (cross-validation, перекрестная валидация)\n",
    "1. **leave-one-out** (отложенный пример)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hold-out** разбиение — исходная выборка разбивается на обучающую и валидационную (+ опционально на тестовую) части в некотором соотношении.\n",
    "\n",
    "Крайне рекомендуемая практика — разбивать выборку на **train/valid/test**. Причина выделения независимой тестовой выборки в том, что она не затрагивается до момента разворачивания алгоритма в сервисе и, соответственно, не используется при настройке параметров алгоритма. Тестирование в таком случае происходит честным путем — полученная на тестовой выборке метрика будет максимально близка к фактически посчитанной метрике в \"боевых условиях\".\n",
    "\n",
    "Мы в дальнейшем будем разбивать выборку на train/valid для упрощения разбора материала.  \n",
    "\n",
    "В каком соотношении делать разбиение?\n",
    "Обычно **на валидационную выборку выделяют по 20-40% данных**. При выделении дополнительно тестовой выборки разбиение можно провести в соотношении **60/20/20%, либо 70/15/15%**. Реальные доли определяются исходя из наличия данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера возьмем известный датасет ирисов. Скачать: https://archive.ics.uci.edu/ml/datasets/iris\n",
    "\n",
    "<img src=\"./pictures/1-2.jpeg\" width=\"500\" align=\"center\">\n",
    "\n",
    "[Источник изображения](https://medium.com/codebagng/basic-analysis-of-the-iris-data-set-using-python-2995618a6342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.read_csv('./data/iris.data', \n",
    "                        names=['sepal_length', 'sepal_width', \n",
    "                               'petal_length', 'petal_width', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5           5.4          3.9           1.7          0.4  Iris-setosa\n",
       "6           4.6          3.4           1.4          0.3  Iris-setosa\n",
       "7           5.0          3.4           1.5          0.2  Iris-setosa\n",
       "8           4.4          2.9           1.4          0.2  Iris-setosa\n",
       "9           4.9          3.1           1.5          0.1  Iris-setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
