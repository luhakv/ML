{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Юнит 5. Основные алгоритмы машинного обучения. Часть I \n",
    "### Skillfactory: DSPR-19\n",
    "### ML-4. Валидация данных и оценка модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### План модуля:\n",
    "\n",
    "- Разбиение выборки.\n",
    "- Метрики качества.\n",
    "- Underfitting и overfitting.\n",
    "- Дисбаланс выборки.\n",
    "- Визуализация процесса обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Разбиение выборки\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разбиение выборки** — это разделение имеющихся данных на несколько частей для проведения процессов обучения и валидации алгоритма МО так, чтобы оба процесса выполнялись на полностью независимых наборах данных.\n",
    "\n",
    "**Какие бывают выборки:**\n",
    "\n",
    "- Обучающая — подмножество данных, на котором мы обучаем модель.\n",
    "- Валидационная — подмножество данных, на котором мы валидируем модель, то есть проверяем промежуточные результаты. Выборка нужна для проверки модели.\n",
    "- Тестовая — подмножество данных, на котором мы тестируем модель после проверки всевозможных гипотез.\n",
    "\n",
    "Обучаем на обучающей выборке: модель явно затачивается под обучающую выборку. Валидируем на валидационной и подкручиваем параметры модели: модель неявно затачивается под валидационную выборку. Тестовая выборка имитирует тестирование модели в реальных условиях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Почему не стоит обучать на всей выборке?\n",
    "Основная цель для нас — это получить модель с хорошей прогностической способностью. Нам не столько важен результат предсказания на нашей выборке (так как на ней нам уже известны все значения признаков), сколько важно уметь предсказывать значения целевой переменной для объектов, которые мы будем исследовать в будущем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как разбить выборку\n",
    "**сomplete CV** — полный скользящий контроль\n",
    "В данном случае оценка строится по всем возможным разбиениям. Важно упомянуть этот метод, однако стоит понимать, что даже при малых размерах длины обучающей выборки число выборки очень большое, и это затрудняет практическое применение данного метода. Полный скользящий контроль используют в теоретических исследованиях или в тех случаях (довольно редких), когда удается вывести вычислительную формулу, позволяющую реализовать вычисления.\n",
    "\n",
    "К примеру, для метода k ближайших соседней такая формула известна, об этом можно почитать тут. Но все же этот метод разбиения используется на практике крайне редко.\n",
    "\n",
    "**hold-out** — отложенная выборка\n",
    "Разбиваем выборку на обучающую, валидационную и, по желанию, на тестовую выборки. Обычно в соотношении 60/40 или 70/30, вместе с тестовой — 60/20/20 или 70/15/15.\n",
    "\n",
    "Данный метод чаще всего применяется в случае больших датасетов в силу того, что требует значительно меньше вычислительных мощностей, чем другие методы.\n",
    "\n",
    "Однако важно помнить, что оценка в этом методе сильно зависит от разбиения. Это плохо, так как оценка должна в первую очередь характеризовать сам алгоритм обучения, а не способ разбиения.\n",
    "\n",
    "**k-fold — cross-validation**, перекрёстная валидация\n",
    "Разбиваем выборку на k частей.\n",
    "Повторяем k раз: обучаем на k-1 частях, валидируем на оставшейся части.\n",
    "Усредняем значения метрики.\n",
    "Позволяет сделать оценку качества более робастной — устойчивой к помехам.\n",
    "Чаще всего k имеет значение 10 (или 5 в случае маленьких выборок).\n",
    "\n",
    "**t×k-fold кросс-валидация**\n",
    "\n",
    "Процедура выполняется t раз. Обучающая выборка случайным образом разбивается на k непересекающихся, одинаковых по объему частей. Производится k итераций. На каждой итерации происходит k-fold-разбиение.\n",
    "\n",
    "По сути, такой тип валидации — это k-fold валидация, которая повторяется t раз. Такой способ контроля обладает всеми преимуществами k-fold-валидации, но при этом добавляется возможность увеличивать число разбиений.\n",
    "\n",
    "**leave-one-out** — отложенный пример\n",
    "Предельный случай k-fold, при котором k равняется размеру всей выборки:\n",
    "\n",
    "Выбираем пример для валидации, обучаем на всех остальных.\n",
    "Выбираем пример для валидации, который ещё не видели, возвращаемся в пункт 1.\n",
    "\n",
    "Частный случай **leave-P-out**, при котором нужно перебрать все способы выбора P-элементов из выборки.  Большим недостатком данного метода является то, что он очень ресурсозатратен. Однако нельзя утверждать, что он вообще не используется. В некоторых методах обучения вычисление LOO получается заметно ускорить, и его использование становится возможным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проблемы при разбиении\n",
    "- Обучение на тестовой выборке.\n",
    "- В тренировочной и тестовой выборках оказываются данные разной природы.\n",
    "Пример: при классификации автомобилей в тренировочную выборку попали примеры с одними типами двигателей, а в тестовую — с другими.\n",
    "- В тренировочной и тестовой выборках оказываются примеры со схожими признаками.\n",
    "Пример: при обучении модели предсказывают пол, разные фотографии одного и того же человека попадают в разные выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
